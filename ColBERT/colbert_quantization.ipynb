{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0de9b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:44.013443Z",
     "iopub.status.busy": "2023-04-01T22:47:44.013031Z",
     "iopub.status.idle": "2023-04-01T22:47:45.136890Z",
     "shell.execute_reply": "2023-04-01T22:47:45.136315Z"
    },
    "papermill": {
     "duration": 1.129283,
     "end_time": "2023-04-01T22:47:45.138605",
     "exception": false,
     "start_time": "2023-04-01T22:47:44.009322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import gc\n",
    "import torch.quantization\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "def timestamp():\n",
    "    print(datetime.datetime.now().strftime(\"%b %d %Y, %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250278f",
   "metadata": {
    "papermill": {
     "duration": 0.002152,
     "end_time": "2023-04-01T22:47:45.143323",
     "exception": false,
     "start_time": "2023-04-01T22:47:45.141171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Quantization of ColBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0172ac82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:45.148499Z",
     "iopub.status.busy": "2023-04-01T22:47:45.148190Z",
     "iopub.status.idle": "2023-04-01T22:47:46.020961Z",
     "shell.execute_reply": "2023-04-01T22:47:46.020229Z"
    },
    "papermill": {
     "duration": 0.877277,
     "end_time": "2023-04-01T22:47:46.022655",
     "exception": false,
     "start_time": "2023-04-01T22:47:45.145378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoConfig\n",
    "from colbert.modeling.colbert import colbert_score\n",
    "from colbert.modeling.checkpoint import Checkpoint\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert import Trainer, Indexer, Searcher\n",
    "from transformers import AutoTokenizer\n",
    "from colbert.data import Queries\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdc040b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.028455Z",
     "iopub.status.busy": "2023-04-01T22:47:46.028151Z",
     "iopub.status.idle": "2023-04-01T22:47:46.032422Z",
     "shell.execute_reply": "2023-04-01T22:47:46.031937Z"
    },
    "papermill": {
     "duration": 0.008621,
     "end_time": "2023-04-01T22:47:46.033690",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.025069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_layers(name, prune_type, ignore_bias=True):\n",
    "    if name.startswith('model.bert.embeddings') \\\n",
    "        or 'LayerNorm' in name: \n",
    "            return True\n",
    "    if ignore_bias and name.endswith('bias'):\n",
    "        return True\n",
    "    if prune_type == \"dense\":\n",
    "        if \"attention\" in name:\n",
    "            return True\n",
    "    elif \"attention\" in prune_type:\n",
    "        if \"attention\" not in name:\n",
    "            return True\n",
    "        if \"no_dense\" in prune_type and \"dense\" in name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb748bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda095ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.039112Z",
     "iopub.status.busy": "2023-04-01T22:47:46.038812Z",
     "iopub.status.idle": "2023-04-01T22:47:46.054218Z",
     "shell.execute_reply": "2023-04-01T22:47:46.053730Z"
    },
    "papermill": {
     "duration": 0.019627,
     "end_time": "2023-04-01T22:47:46.055435",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.035808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantization_data_new(config, quant_type, quant_Int):\n",
    "    use_iter = \"v2.0\"\n",
    "    \n",
    "    use_full_data = False\n",
    "    nbits = 2\n",
    "    k = 1000\n",
    "    maxsteps = 10000\n",
    "\n",
    "    base_path = fr\"experiments/\"\n",
    "    experiment = fr\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #use_iter_str=f\"{use_iter:,}\".replace(',','.')\n",
    "    index_name = f\"\"\n",
    "\n",
    "\n",
    "    checkpoint = fr\"experiments/model_dump/colbert{use_iter}\" \n",
    "    retrieval_name = f\"{index_name}.ranking={k}.tsv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if not os.path.exists(checkpoint):\n",
    "        #anil checkpoint = fr\"{base_path}/checkpoints/colbert\"\n",
    "        print(f\"Couldn't find checkpoint. Using default checkpoint: {checkpoint}\")\n",
    "        checkpoint = fr\"experiments/model_dump/colbertv2.0\"\n",
    "\n",
    "    config = ColBERTConfig(\n",
    "        bsize = 64,\n",
    "        root=base_path,\n",
    "        experiment=experiment,\n",
    "        triples=r\"../../data/triples.train.small.id.json\",\n",
    "        collection= r\"../../data/collection.tsv\",\n",
    "\n",
    "        checkpoint=checkpoint,\n",
    "        nbits=nbits,\n",
    "        overwrite='resume',\n",
    "        index_name=index_name,\n",
    "        index_path=fr\"./indexes\",\n",
    "        rank = 0,\n",
    "        nranks = 1,\n",
    "        amp = True,\n",
    "        gpus = 1,\n",
    "    )\n",
    "\n",
    "    print(\"index_name=\",index_name)\n",
    "        \n",
    "    for q_type in quant_type:\n",
    "        print(f\"Quantizing model on quantization type {q_type} to: {quant_Int}\")\n",
    "        with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment)):\n",
    "            model = Checkpoint(config.checkpoint, colbert_config=config)\n",
    "        model_state_dict = model.state_dict()\n",
    "        quantized_model = torch.quantization.quantize_dynamic(model,q_type , dtype=quant_Int)\n",
    "        quantized_state_dict = quantized_model.state_dict()       \n",
    "        print_size_of_model(model)\n",
    "        print_size_of_model(quantized_model)\n",
    "        \n",
    "        if do_retrieval:\n",
    "            timestamp()\n",
    "            gc.collect()\n",
    "            config.set(\"queries\", r\"../../data/queries.dev.small.tsv\")\n",
    "            \n",
    "  \n",
    "            with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment, name='retrieval', overwrite = True)):\n",
    "                \n",
    "                config.checkpoint = model\n",
    "                model.to('cpu')\n",
    "                searcher = Searcher(index=config.index_name, config=config, checkpoint=model)\n",
    "                queries = Queries(config.queries)\n",
    "                count = 0\n",
    "                while(count !=5):\n",
    "                    print(f\"Base model #\", count)\n",
    "                    ranking = searcher.search_all(queries, k=k)\n",
    "                    count = count + 1\n",
    "            timestamp()\n",
    "\n",
    "            del searcher, queries, ranking\n",
    "            gc.collect()\n",
    "            \n",
    "            with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment, name='retrieval', overwrite = True)):\n",
    "                \n",
    "                config.checkpoint = quantized_model\n",
    "                quantized_model.to('cpu')\n",
    "                searcher = Searcher(index=config.index_name, config=config, checkpoint=quantized_model)\n",
    "                queries = Queries(config.queries)\n",
    "                count = 0\n",
    "                while(count !=5):\n",
    "                    print(f\"Quantized model #\", count)\n",
    "                    ranking = searcher.search_all(queries, k=k)\n",
    "                    count = count + 1\n",
    "                #ranking.save(f\"msmarco.{use_iter}.nbits={config.nbits}.prune={prune_amount}.prune_type={prune_type}.ranking={k}.tsv\")\n",
    "                #ranking.save(retrieval_name)\n",
    "            timestamp()\n",
    "\n",
    "            del searcher, queries, ranking\n",
    "            gc.collect()\n",
    "             \n",
    "\n",
    "        if do_eval:\n",
    "            #!python -m utility.evaluate.msmarco_passages \\\n",
    "            #     --ranking \"experiments/msmarco_{maxsteps_str}/retrieval/msmarco.{use_iter}.nbits={config.nbits}.prune={prune_amount}.prune_type={prune_type}.ranking={k}.tsv\" \\\n",
    "            #     --qrels \"../data/qrels.dev.tsv\" > \"experiments/msmarco_{maxsteps_str}/retrieval/msmarco.{use_iter}.nbits={config.nbits}.prune={prune_amount}.prune_type={prune_type}.ranking={k}.tsv.log\"\n",
    "            !python -m utility.evaluate.msmarco_passages \\\n",
    "                --ranking \"experiments/{experiment}/none/retrieval/{retrieval_name}\" \\\n",
    "                --qrels \"../../data/qrels.dev.small.tsv\" #> \"experiments/{experiment}/retrieval/{retrieval_name}.log\"\n",
    "        del model,quantized_model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56868123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.060671Z",
     "iopub.status.busy": "2023-04-01T22:47:46.060344Z",
     "iopub.status.idle": "2023-04-01T22:47:46.064450Z",
     "shell.execute_reply": "2023-04-01T22:47:46.063968Z"
    },
    "papermill": {
     "duration": 0.008156,
     "end_time": "2023-04-01T22:47:46.065733",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.057577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantization_data(config, quant_type, quant_Int):\n",
    "\n",
    "    for q_type in quant_type:\n",
    "        print(f\"Quantizing model on Quantization type {q_type} to: {quant_Int}\")\n",
    "        with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment)):\n",
    "            model = Checkpoint(config.checkpoint, colbert_config=config)\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        quantized_model = torch.quantization.quantize_dynamic(model,q_type , dtype=quant_Int)\n",
    "        quantized_model.save(f\"{checkpoint}.quant={quant_Int}.quant_type={q_type}\")\n",
    "        del model,quantized_model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73390957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.071026Z",
     "iopub.status.busy": "2023-04-01T22:47:46.070721Z",
     "iopub.status.idle": "2023-04-01T22:47:46.073361Z",
     "shell.execute_reply": "2023-04-01T22:47:46.072875Z"
    },
    "papermill": {
     "duration": 0.00665,
     "end_time": "2023-04-01T22:47:46.074594",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.067944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "quantization_Int = [torch.qint8]\n",
    "quantization_Type = [{torch.nn.Linear}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41943553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.079925Z",
     "iopub.status.busy": "2023-04-01T22:47:46.079625Z",
     "iopub.status.idle": "2023-04-02T00:10:24.080386Z",
     "shell.execute_reply": "2023-04-02T00:10:24.079725Z"
    },
    "papermill": {
     "duration": 4959.330719,
     "end_time": "2023-04-02T00:10:25.407498",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.076779",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_name= \n",
      "pruning model on prune type {<class 'torch.nn.modules.linear.Linear'>} to: torch.qint8\n",
      "Size (MB): 438.393806\n",
      "Size (MB): 181.584042\n",
      "Apr 09 2023, 16:48:35\n",
      "[Apr 09, 16:48:36] #> Loading collection...\n",
      "0M 1M 2M 3M 4M 5M 6M 7M 8M \n",
      "[Apr 09, 16:48:58] #> Loading codec...\n",
      "[Apr 09, 16:48:58] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Apr 09, 16:48:59] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Apr 09, 16:49:03] #> Loading IVF...\n",
      "[Apr 09, 16:49:14] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:00<00:00, 630.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 09, 16:49:15] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [02:42<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 09, 16:51:58] #> Loading the queries from ../../data/queries.dev.small.tsv ...\n",
      "[Apr 09, 16:51:58] #> Got 6980 queries. All QIDs are unique.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model # 0\n",
      "Encoding Start\n",
      "Apr 09 2023, 16:51:58\n",
      "Apr 09 2023, 16:52:47\n",
      "Encoding End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6980/6980 [04:15<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model # 1\n",
      "Encoding Start\n",
      "Apr 09 2023, 16:57:08\n",
      "Apr 09 2023, 16:57:57\n",
      "Encoding End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6980/6980 [04:06<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model # 2\n",
      "Encoding Start\n",
      "Apr 09 2023, 17:02:10\n",
      "Apr 09 2023, 17:02:53\n",
      "Encoding End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6980/6980 [04:06<00:00, 28.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model # 3\n",
      "Encoding Start\n",
      "Apr 09 2023, 17:07:05\n",
      "Apr 09 2023, 17:07:48\n",
      "Encoding End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6980/6980 [04:07<00:00, 28.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model # 4\n",
      "Encoding Start\n",
      "Apr 09 2023, 17:12:01\n",
      "Apr 09 2023, 17:12:47\n",
      "Encoding End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6980/6980 [04:08<00:00, 28.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apr 09 2023, 17:17:02\n",
      "[Apr 09, 17:17:06] #> Loading collection...\n",
      "0M 1M 2M 3M 4M 5M 6M 7M 8M \n",
      "[Apr 09, 17:17:20] #> Loading codec...\n",
      "[Apr 09, 17:17:20] #> Loading IVF...\n",
      "[Apr 09, 17:17:21] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:00<00:00, 1275.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 09, 17:17:21] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:09<00:00, 36.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 09, 17:17:31] #> Loading the queries from ../../data/queries.dev.small.tsv ...\n",
      "[Apr 09, 17:17:31] #> Got 6980 queries. All QIDs are unique.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model # 0\n",
      "Encoding Start\n",
      "Apr 09 2023, 17:17:31\n",
      "Apr 09 2023, 17:18:02\n",
      "Encoding End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6980/6980 [04:28<00:00, 26.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model # 1\n",
      "Encoding Start\n",
      "Apr 09 2023, 17:22:37\n",
      "Apr 09 2023, 17:23:16\n",
      "Encoding End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6980/6980 [04:28<00:00, 25.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model # 2\n",
      "Encoding Start\n",
      "Apr 09 2023, 17:27:51\n",
      "Apr 09 2023, 17:28:29\n",
      "Encoding End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████▍     | 6607/6980 [04:15<00:14, 25.56it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "#if not os.path.exists(checkpoint):\n",
    "#    checkpoint = fr\"{base_path}/checkpoints/colbert\"\n",
    "base_path = fr\"experiments/\"\n",
    "checkpoint = fr\"experiments/model_dump/colbertv2.0\"\n",
    "\n",
    "do_retrieval = True\n",
    "do_eval = True\n",
    "    \n",
    "config = ColBERTConfig(\n",
    "        bsize = 64,\n",
    "        root=base_path,\n",
    "    \n",
    "        triples=r\"../../data/triples.train.small.id.json\",\n",
    "        collection= r\"../../data/collection.tsv\",\n",
    "        \n",
    "        checkpoint = checkpoint,\n",
    "        overwrite='resume',\n",
    "    \n",
    "        ncells= 10,\n",
    "    \n",
    "        rank = 0,\n",
    "        nranks = 1,\n",
    "        amp = True,\n",
    "        gpus = 1,\n",
    "    )\n",
    "\n",
    "for q_Int in quantization_Int:\n",
    "    quantization_data_new(config, quantization_Type, q_Int )\n",
    "print(\"quantization experiment complete\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4969.626694,
   "end_time": "2023-04-02T00:10:32.479354",
   "environment_variables": {},
   "exception": true,
   "input_path": "anil_quantization.ipynb",
   "output_path": "anil_quantization_output1.ipynb",
   "parameters": {},
   "start_time": "2023-04-01T22:47:42.852660",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
