{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0de9b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:44.013443Z",
     "iopub.status.busy": "2023-04-01T22:47:44.013031Z",
     "iopub.status.idle": "2023-04-01T22:47:45.136890Z",
     "shell.execute_reply": "2023-04-01T22:47:45.136315Z"
    },
    "papermill": {
     "duration": 1.129283,
     "end_time": "2023-04-01T22:47:45.138605",
     "exception": false,
     "start_time": "2023-04-01T22:47:44.009322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import gc\n",
    "import torch.quantization\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "def timestamp():\n",
    "    print(datetime.datetime.now().strftime(\"%b %d %Y, %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250278f",
   "metadata": {
    "papermill": {
     "duration": 0.002152,
     "end_time": "2023-04-01T22:47:45.143323",
     "exception": false,
     "start_time": "2023-04-01T22:47:45.141171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0172ac82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:45.148499Z",
     "iopub.status.busy": "2023-04-01T22:47:45.148190Z",
     "iopub.status.idle": "2023-04-01T22:47:46.020961Z",
     "shell.execute_reply": "2023-04-01T22:47:46.020229Z"
    },
    "papermill": {
     "duration": 0.877277,
     "end_time": "2023-04-01T22:47:46.022655",
     "exception": false,
     "start_time": "2023-04-01T22:47:45.145378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoConfig\n",
    "from colbert.modeling.colbert import colbert_score\n",
    "from colbert.modeling.checkpoint import Checkpoint\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert import Trainer, Indexer, Searcher\n",
    "from transformers import AutoTokenizer\n",
    "from colbert.data import Queries\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdc040b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.028455Z",
     "iopub.status.busy": "2023-04-01T22:47:46.028151Z",
     "iopub.status.idle": "2023-04-01T22:47:46.032422Z",
     "shell.execute_reply": "2023-04-01T22:47:46.031937Z"
    },
    "papermill": {
     "duration": 0.008621,
     "end_time": "2023-04-01T22:47:46.033690",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.025069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_layers(name, prune_type, ignore_bias=True):\n",
    "    if name.startswith('model.bert.embeddings') \\\n",
    "        or 'LayerNorm' in name: \n",
    "            return True\n",
    "    if ignore_bias and name.endswith('bias'):\n",
    "        return True\n",
    "    if prune_type == \"dense\":\n",
    "        if \"attention\" in name:\n",
    "            return True\n",
    "    elif \"attention\" in prune_type:\n",
    "        if \"attention\" not in name:\n",
    "            return True\n",
    "        if \"no_dense\" in prune_type and \"dense\" in name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda095ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.039112Z",
     "iopub.status.busy": "2023-04-01T22:47:46.038812Z",
     "iopub.status.idle": "2023-04-01T22:47:46.054218Z",
     "shell.execute_reply": "2023-04-01T22:47:46.053730Z"
    },
    "papermill": {
     "duration": 0.019627,
     "end_time": "2023-04-01T22:47:46.055435",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.035808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantization_data_new(config, quant_type, quant_Int):\n",
    "    use_iter = \"v2.0\"\n",
    "    \n",
    "    use_full_data = False\n",
    "    nbits = 2\n",
    "    k = 1000\n",
    "    maxsteps = 10000\n",
    "\n",
    "    base_path = fr\"experiments/\"\n",
    "    maxsteps_str=f\"10.000\"\n",
    "\n",
    "    base_path = fr\"experiments/\"\n",
    "    maxsteps_str=f\"{maxsteps:,}\".replace(',','.')\n",
    "    experiment = f\"msmarco_{maxsteps_str}\"\n",
    "    if use_full_data:\n",
    "        experiment += f\".data=full\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #use_iter_str=f\"{use_iter:,}\".replace(',','.')\n",
    "    index_name = f\"msmarco_{maxsteps_str}{'.data=full' if use_full_data else ''}.nbits={nbits}\"\n",
    "\n",
    "\n",
    "    checkpoint = fr\"experiments/model_dump/colbert{use_iter}\" \n",
    "    retrieval_name = f\"{index_name}.ranking={k}.tsv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if not os.path.exists(checkpoint):\n",
    "        #anil checkpoint = fr\"{base_path}/checkpoints/colbert\"\n",
    "        print(f\"Couldn't find checkpoint. Using default checkpoint: {checkpoint}\")\n",
    "        checkpoint = fr\"experiments/model_dump/colbertv2.0\"\n",
    "\n",
    "    config = ColBERTConfig(\n",
    "        bsize = 64,\n",
    "        root=base_path,\n",
    "        experiment=experiment,\n",
    "\n",
    "\n",
    "        #anil triples=r\"../data/triples.train.small.id.json\",\n",
    "        #anil collection= r\"../data/collection.tsv\",\n",
    "        triples=r\"../kngo/data/triples.train.small.id.json\",\n",
    "        collection= r\"../kngo/data/collection.tsv\",\n",
    "\n",
    "        checkpoint=checkpoint,\n",
    "        nbits=nbits,\n",
    "        overwrite='resume',\n",
    "        index_name=index_name,\n",
    "        index_path=fr\"/home/ubuntu/capstone/colbert/experiments/indexes/msmarco_10.000.nbits=2\",\n",
    "\n",
    "        rank = 0,\n",
    "        nranks = 1,\n",
    "        amp = True,\n",
    "        gpus = 1,\n",
    "    )\n",
    "\n",
    "    print(\"index_name=\",index_name)\n",
    "        \n",
    "    for q_type in quant_type:\n",
    "        print(f\"pruning model on prune type {q_type} to: {quant_Int}\")\n",
    "        with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment)):\n",
    "            model = Checkpoint(config.checkpoint, colbert_config=config)\n",
    "\n",
    "        #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        #model.to(device)\n",
    "        model_state_dict = model.state_dict()\n",
    "        #for key, weight in model_state_dict.items():\n",
    "        #    print(\"key1=\",key,\",weight1 = \",weight)\n",
    "        quantized_model = torch.quantization.quantize_dynamic(model,q_type , dtype=quant_Int)\n",
    "        #quantized_model.save(\"pegasus-quantized-config\")\n",
    "        #model.config.save_pretrained(\"pegasus-quantized-config\")\n",
    "        #quantized_model.model.save_pretrained(\"pegasus-quantized-config\")\n",
    "        quantized_state_dict = quantized_model.state_dict()\n",
    "        #quantized_state_dict1 = {key.replace('model.', ''): quantized_state_dict.pop(key) for key in quantized_state_dict.keys()}\n",
    "        #torch.save(quantized_state_dict, \"pytorch_model.pt\")\n",
    "\n",
    "        #print(model)\n",
    "        #print(quantized_model)\n",
    "        #checkpoint = fr\"pegasus-quantized-config\"\n",
    "        #quantized_model.save(f\"lalal\")\n",
    "        def print_size_of_model(model):\n",
    "            torch.save(model.state_dict(), \"temp.p\")\n",
    "            print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "            os.remove('temp.p')\n",
    "            \n",
    "        #for key, weight in quantized_state_dict.items():\n",
    "        #    print(\"key2=\",key,\",weight2 = \",weight)\n",
    "       \n",
    "        print_size_of_model(model)\n",
    "        print_size_of_model(quantized_model)\n",
    "        \n",
    "        if do_retrieval:\n",
    "            timestamp()\n",
    "            gc.collect()\n",
    "            config.set(\"queries\", r\"../kngo/data/queries.dev.tsv\")\n",
    "            \n",
    "  \n",
    "            with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment, name='retrieval', overwrite = True)):\n",
    "                \n",
    "                config.checkpoint = model\n",
    "                model.to('cpu')\n",
    "                searcher = Searcher(index=config.index_name, config=config, checkpoint=model)\n",
    "                queries = Queries(config.queries)\n",
    "                count = 0\n",
    "                while(count !=10):\n",
    "                    print(f\"Base model #\", count)\n",
    "                    ranking = searcher.search_all(queries, k=k)\n",
    "                    count = count + 1\n",
    "                #ranking.save(f\"msmarco.{use_iter}.nbits={config.nbits}.prune={prune_amount}.prune_type={prune_type}.ranking={k}.tsv\")\n",
    "                #ranking.save(retrieval_name)\n",
    "            timestamp()\n",
    "\n",
    "            del searcher, queries, ranking\n",
    "            gc.collect()\n",
    "            \n",
    "            with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment, name='retrieval', overwrite = True)):\n",
    "                \n",
    "                config.checkpoint = quantized_model\n",
    "                quantized_model.to('cpu')\n",
    "                searcher = Searcher(index=config.index_name, config=config, checkpoint=quantized_model)\n",
    "                queries = Queries(config.queries)\n",
    "                count = 0\n",
    "                while(count !=10):\n",
    "                    print(f\"Quantized model #\", count)\n",
    "                    ranking = searcher.search_all(queries, k=k)\n",
    "                    count = count + 1\n",
    "                #ranking.save(f\"msmarco.{use_iter}.nbits={config.nbits}.prune={prune_amount}.prune_type={prune_type}.ranking={k}.tsv\")\n",
    "                #ranking.save(retrieval_name)\n",
    "            timestamp()\n",
    "\n",
    "            del searcher, queries, ranking\n",
    "            gc.collect()\n",
    "             \n",
    "\n",
    "        if do_eval:\n",
    "            #!python -m utility.evaluate.msmarco_passages \\\n",
    "            #     --ranking \"experiments/msmarco_{maxsteps_str}/retrieval/msmarco.{use_iter}.nbits={config.nbits}.prune={prune_amount}.prune_type={prune_type}.ranking={k}.tsv\" \\\n",
    "            #     --qrels \"../data/qrels.dev.tsv\" > \"experiments/msmarco_{maxsteps_str}/retrieval/msmarco.{use_iter}.nbits={config.nbits}.prune={prune_amount}.prune_type={prune_type}.ranking={k}.tsv.log\"\n",
    "            !python -m utility.evaluate.msmarco_passages \\\n",
    "                --ranking \"experiments/{experiment}/none/retrieval/{retrieval_name}\" \\\n",
    "                --qrels \"../kngo/data/qrels.dev.tsv\" #> \"experiments/{experiment}/retrieval/{retrieval_name}.log\"\n",
    "        del model,quantized_model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56868123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.060671Z",
     "iopub.status.busy": "2023-04-01T22:47:46.060344Z",
     "iopub.status.idle": "2023-04-01T22:47:46.064450Z",
     "shell.execute_reply": "2023-04-01T22:47:46.063968Z"
    },
    "papermill": {
     "duration": 0.008156,
     "end_time": "2023-04-01T22:47:46.065733",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.057577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantization_data(config, quant_type, quant_Int):\n",
    "\n",
    "    for q_type in quant_type:\n",
    "        print(f\"pruning model on prune type {q_type} to: {quant_Int}\")\n",
    "        with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment)):\n",
    "            model = Checkpoint(config.checkpoint, colbert_config=config)\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        quantized_model = torch.quantization.quantize_dynamic(model,q_type , dtype=quant_Int)\n",
    "        quantized_model.save(f\"{checkpoint}.quant={quant_Int}.quant_type={q_type}\")\n",
    "        del model,quantized_model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73390957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.071026Z",
     "iopub.status.busy": "2023-04-01T22:47:46.070721Z",
     "iopub.status.idle": "2023-04-01T22:47:46.073361Z",
     "shell.execute_reply": "2023-04-01T22:47:46.072875Z"
    },
    "papermill": {
     "duration": 0.00665,
     "end_time": "2023-04-01T22:47:46.074594",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.067944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "quantization_Int = [torch.qint8]\n",
    "quantization_Type = [{torch.nn.Linear}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41943553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:47:46.079925Z",
     "iopub.status.busy": "2023-04-01T22:47:46.079625Z",
     "iopub.status.idle": "2023-04-02T00:10:24.080386Z",
     "shell.execute_reply": "2023-04-02T00:10:24.079725Z"
    },
    "papermill": {
     "duration": 4959.330719,
     "end_time": "2023-04-02T00:10:25.407498",
     "exception": false,
     "start_time": "2023-04-01T22:47:46.076779",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find checkpoint. Using default checkpoint: experiments/model_dump/colbertv2.0\n",
      "index_name= msmarco_10.000.nbits=2\n",
      "pruning model on prune type {<class 'torch.nn.modules.linear.Linear'>} to: torch.qint8\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of 'experiments/model_dump/colbertv2.0'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'experiments/model_dump/colbertv2.0' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/colbert/lib/python3.8/site-packages/transformers/configuration_utils.py:620\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001b[0;32m/opt/conda/envs/colbert/lib/python3.8/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m/opt/conda/envs/colbert/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/colbert/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:166\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'experiments/model_dump/colbertv2.0'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m      9\u001b[0m config \u001b[38;5;241m=\u001b[39m ColBERTConfig(\n\u001b[1;32m     10\u001b[0m         bsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     11\u001b[0m         root\u001b[38;5;241m=\u001b[39mbase_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m         gpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q_Int \u001b[38;5;129;01min\u001b[39;00m quantization_Int:\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mquantization_data_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_Type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_Int\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m, in \u001b[0;36mquantization_data_new\u001b[0;34m(config, quant_type, quant_Int)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruning model on prune type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquant_Int\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Run()\u001b[38;5;241m.\u001b[39mcontext(RunConfig(nranks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnranks, experiment\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperiment)):\n\u001b[0;32m---> 64\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolbert_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#model.to(device)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m model_state_dict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "File \u001b[0;32m~/capstone/repo/ColBERT/colbert/modeling/checkpoint.py:19\u001b[0m, in \u001b[0;36mCheckpoint.__init__\u001b[0;34m(self, name, colbert_config)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, colbert_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolbert_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_tokenizer \u001b[38;5;241m=\u001b[39m QueryTokenizer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolbert_config)\n",
      "File \u001b[0;32m~/capstone/repo/ColBERT/colbert/modeling/colbert.py:20\u001b[0m, in \u001b[0;36mColBERT.__init__\u001b[0;34m(self, name, colbert_config)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, colbert_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolbert_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;241m=\u001b[39m colbert_config\u001b[38;5;241m.\u001b[39mtotal_visible_gpus \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     23\u001b[0m     ColBERT\u001b[38;5;241m.\u001b[39mtry_load_torch_extensions(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gpu)\n",
      "File \u001b[0;32m~/capstone/repo/ColBERT/colbert/modeling/base_colbert.py:32\u001b[0m, in \u001b[0;36mBaseColBERT.__init__\u001b[0;34m(self, name_or_path, colbert_config)\u001b[0m\n\u001b[1;32m     29\u001b[0m     HF_ColBERT \u001b[38;5;241m=\u001b[39m class_factory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m HF_ColBERT \u001b[38;5;241m=\u001b[39m \u001b[43mclass_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m HF_ColBERT\u001b[38;5;241m.\u001b[39mfrom_pretrained(name_or_path, colbert_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolbert_config)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(name_or_path)\n",
      "File \u001b[0;32m~/capstone/repo/ColBERT/colbert/modeling/hf_colbert.py:59\u001b[0m, in \u001b[0;36mclass_factory\u001b[0;34m(name_or_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclass_factory\u001b[39m(name_or_path):\n\u001b[0;32m---> 59\u001b[0m     loadedConfig  \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m loadedConfig\u001b[38;5;241m.\u001b[39mmodel_type\n\u001b[1;32m     61\u001b[0m     pretrained_class \u001b[38;5;241m=\u001b[39m find_class_names(model_type, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrainedmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/colbert/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:852\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    851\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 852\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m/opt/conda/envs/colbert/lib/python3.8/site-packages/transformers/configuration_utils.py:565\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    567\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/colbert/lib/python3.8/site-packages/transformers/configuration_utils.py:641\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;66;03m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load the configuration of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name. Otherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m containing a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfiguration_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    646\u001b[0m         )\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;66;03m# Load config dict\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of 'experiments/model_dump/colbertv2.0'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'experiments/model_dump/colbertv2.0' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "\n",
    "#if not os.path.exists(checkpoint):\n",
    "#    checkpoint = fr\"{base_path}/checkpoints/colbert\"\n",
    "base_path = fr\"experiments/\"\n",
    "checkpoint = fr\"experiments/model_dump/colbertv2.0\"\n",
    "\n",
    "do_retrieval = True\n",
    "do_eval = True\n",
    "    \n",
    "config = ColBERTConfig(\n",
    "        bsize = 64,\n",
    "        root=base_path,\n",
    "    \n",
    "        triples=r\"../kngo/data/triples.train.small.id.json\",\n",
    "        collection= r\"../kngo/data/collection.tsv\",\n",
    "        \n",
    "        checkpoint = checkpoint,\n",
    "        overwrite='resume',\n",
    "    \n",
    "        ncells= 10,\n",
    "    \n",
    "        rank = 0,\n",
    "        nranks = 1,\n",
    "        amp = True,\n",
    "        gpus = 1,\n",
    "    )\n",
    "\n",
    "for q_Int in quantization_Int:\n",
    "    quantization_data_new(config, quantization_Type, q_Int )\n",
    "print(\"quantization complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1ee1c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36cecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T00:10:28.046794Z",
     "iopub.status.busy": "2023-04-02T00:10:28.046437Z",
     "iopub.status.idle": "2023-04-02T00:10:28.184308Z",
     "shell.execute_reply": "2023-04-02T00:10:28.183593Z"
    },
    "papermill": {
     "duration": 1.456666,
     "end_time": "2023-04-02T00:10:28.185451",
     "exception": true,
     "start_time": "2023-04-02T00:10:26.728785",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for p_amount in prune_amount:\n",
    "    gc.collect()\n",
    "    prune_experiment(prune_type, p_amount, maxsteps = 10000,  k = 1000, \\\n",
    "                     do_train = False, do_index = False, do_retrieval = False, do_eval = True, nbits = 2, \\\n",
    "                     use_full_data = False)\n",
    "print(\"!!!!all done!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fba3f5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e68199",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#input_ids = ids_tensor([8, 128], 2)\n",
    "#token_type_ids = ids_tensor([8, 128], 2)\n",
    "#attention_mask = ids_tensor([8, 128], vocab_size=2)\n",
    "#dummy_input = (input_ids, attention_mask, token_type_ids)\n",
    "#traced_model = torch.jit.trace(quantized_model, dummy_input)\n",
    "#torch.jit.save(traced_model, \"bert_traced_eager_quant.pt\")\n",
    "#print(\"Saved the model\")\n",
    "\n",
    "# save config\n",
    "#quantized_model.config.save_pretrained(\"pegasus-quantized-config\")\n",
    "# save state dict\n",
    "#quantized_state_dict = quantized_model.state_dict()\n",
    "#torch.save(quantized_state_dict, \"pegasus-quantized.pt\")\n",
    "\n",
    "\n",
    "# load config and dummy model\n",
    "#config = AutoConfig.from_pretrained(\"pegasus-quantized-config\")\n",
    "#dummy_model = PegasusForConditionalGeneration(config)\n",
    "#4. quantize dummy model and load state dict\n",
    "#reconstructed_quantized_model = torch.quantization.quantize_dynamic(\n",
    "#    dummy_model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "#)\n",
    "#reconstructed_quantized_model.load_state_dict(quantized_state_dict)\n",
    "\n",
    "\n",
    "\n",
    "config.set(\"queries\", r\"../kngo/data/queries.dev_clean.tsv\" \n",
    "           if os.path.exists(r\"../kngo/data/queries.dev_clean.tsv\") \n",
    "           else r\"../kngo/data/queries.small.dev.tsv\")\n",
    "with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment, name='retrieval', overwrite = True)):\n",
    "    print(\"lala=\",config.index_name, quantized_model, retrieval_name, experiment)\n",
    "\n",
    "    searcher = Searcher(index=config.index_name, config=config, checkpoint=quantized_model)\n",
    "    queries = Queries(config.queries)\n",
    "    ranking = searcher.search_all(queries, k=k)\n",
    "    #ranking.save(f\"msmarco.{use_iter}.nbits={config.nbits}.prune={prune_amount}.prune_type={prune_type}.ranking={k}.tsv\")\n",
    "    ranking.save(retrieval_name)\n",
    "timestamp()\n",
    "\n",
    "del searcher, queries, ranking\n",
    "gc.collect()\n",
    "\n",
    "!python -m utility.evaluate.msmarco_passages \\\n",
    "    --ranking \"experiments/{experiment}/none/retrieval/{retrieval_name}\" \\\n",
    "    --qrels \"../kngo/data/qrels.dev.tsv\" #> \"experiments/{experiment}/retrieval/{retrieval_name}.log\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aba086",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig\n",
    "#experimentsmsmarco_10.000indexesmsmarco_10.000.nbits=2\n",
    "\n",
    "use_full_data = False\n",
    "do_train = False\n",
    "do_index = False\n",
    "do_retrieval = False\n",
    "do_eval = True\n",
    "nbits = 2\n",
    "use_iter = \"v2.0\"\n",
    "k = 1000\n",
    "\n",
    "base_path = fr\"experiments/\"\n",
    "maxsteps_str=f\"10.000\"\n",
    "experiment = f\"msmarco_{maxsteps_str}\"\n",
    "if use_full_data:\n",
    "    experiment += f\".data=full\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#use_iter_str=f\"{use_iter:,}\".replace(',','.')\n",
    "index_name = f\"msmarco_{maxsteps_str}{'.data=full' if use_full_data else ''}.nbits={nbits}\"\n",
    "\n",
    "\n",
    "checkpoint = fr\"experiments/model_dump/colbert{use_iter}\" \n",
    "retrieval_name = f\"{index_name}.ranking={k}.tsv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(checkpoint):\n",
    "    #anil checkpoint = fr\"{base_path}/checkpoints/colbert\"\n",
    "    print(f\"Couldn't find checkpoint. Using default checkpoint: {checkpoint}\")\n",
    "    checkpoint = fr\"experiments/model_dump/colbertv2.0\"\n",
    "\n",
    "config = ColBERTConfig(\n",
    "    bsize = 64,\n",
    "    root=base_path,\n",
    "    experiment=experiment,\n",
    "    name=experiment,\n",
    "\n",
    "\n",
    "    #anil triples=r\"../data/triples.train.small.id.json\",\n",
    "    #anil collection= r\"../data/collection.tsv\",\n",
    "    triples=r\"../kngo/data/triples.train.small.id.json\",\n",
    "    collection= r\"../kngo/data/collection.tsv\",\n",
    "\n",
    "    checkpoint=checkpoint,\n",
    "    nbits=nbits,\n",
    "    overwrite='resume',\n",
    "    index_name=index_name,\n",
    "    index_path=fr\"{base_path}indexes/{index_name}\",\n",
    "\n",
    "    rank = 0,\n",
    "    nranks = 1,\n",
    "    amp = True,\n",
    "    gpus = 1,\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "with Run().context(RunConfig(nranks=config.nranks, experiment=config.experiment)):\n",
    "    model = Checkpoint(config.checkpoint, colbert_config=config)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# quantize model\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "print_size_of_model(model)\n",
    "print_size_of_model(quantized_model)\n",
    "\n",
    "#quantized_model.model.save_pretrained(\"tmp-t5-small-quantized-config\")  # save config\n",
    "quantized_state_dict = quantized_model.state_dict()\n",
    "#for key, weight in quantized_state_dict.items():\n",
    "#    print(key,weight)\n",
    "#torch.jit.save(quantized_state_dict, \"tmp-t5-small-quantized-state-dict.pt\")\n",
    "torch.save(quantized_state_dict, \"tmp-t5-small-quantized-state-dict.pt\")\n",
    "\n",
    "# Transform your model into a quantized model\n",
    "quantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "# Load the quantized weights into the quantized model (module in torch)\n",
    "quantized_model.load_state_dict(torch.load(\"tmp-t5-small-quantized-state-dict.pt\"))\n",
    "\n",
    "print('Load quantized model')\n",
    "#quantized_config = AutoConfig.from_pretrained(\"tmp-t5-small-quantized-config\")\n",
    "#dummy_model = ColBERT(quantized_config)\n",
    "\n",
    "#reconstructed_quantized_model = torch.quantization.quantize_dynamic(\n",
    "#    dummy_model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "#)\n",
    "#reconstructed_quantized_model.load_state_dict(torch.load(\"tmp-t5-small-quantized-state-dict.pt\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d45ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from argparse import Namespace\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from tqdm import tqdm\n",
    "from transformers import (BertConfig, BertForSequenceClassification, BertTokenizer,)\n",
    "from transformers import glue_compute_metrics as compute_metrics\n",
    "from transformers import glue_output_modes as output_modes\n",
    "from transformers import glue_processors as processors\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "from torch.quantization import per_channel_dynamic_qconfig\n",
    "from torch.quantization import quantize_dynamic_jit\n",
    "\n",
    "global_rng = random.Random()\n",
    "\n",
    "def ids_tensor(shape, vocab_size, rng=None, name=None):\n",
    "    #  Creates a random int32 tensor of the shape within the vocab size\n",
    "    if rng is None:\n",
    "        rng = global_rng\n",
    "\n",
    "    total_dims = 1\n",
    "    for dim in shape:\n",
    "        total_dims *= dim\n",
    "\n",
    "    values = []\n",
    "    for _ in range(total_dims):\n",
    "        values.append(rng.randint(0, vocab_size - 1))\n",
    "\n",
    "    return torch.tensor(data=values, dtype=torch.long, device='cpu').view(shape).contiguous()\n",
    "\n",
    "# Setup logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.WARN)\n",
    "\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(\n",
    "   logging.WARN)  # Reduce logging\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "print(torch.__config__.parallel_info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4969.626694,
   "end_time": "2023-04-02T00:10:32.479354",
   "environment_variables": {},
   "exception": true,
   "input_path": "anil_quantization.ipynb",
   "output_path": "anil_quantization_output1.ipynb",
   "parameters": {},
   "start_time": "2023-04-01T22:47:42.852660",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
